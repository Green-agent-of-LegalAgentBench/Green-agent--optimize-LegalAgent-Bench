# scripts/run_audit_resume.py

from __future__ import annotations

import requests
import os
import sys

# å…³é”®ï¼šæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ Python è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import argparse
import json
import time
from typing import Any, Dict, List, Optional, Set

from tqdm import tqdm

from src.green_rag_engine import GreenRAGEngine
from src.traffic_light_eval import TrafficLightAuditor
# scripts/run_audit_resume.py
def _unwrap_raw_audit(obj, max_depth=10):
    depth = 0
    cur = obj
    while depth < max_depth and isinstance(cur, dict) and isinstance(cur.get("raw_audit"), dict):
        cur = cur["raw_audit"]
        depth += 1
    return cur

def _sanitize_record(rec: dict) -> dict:
    ra = rec.get("raw_audit")
    inner = _unwrap_raw_audit(ra)
    if isinstance(inner, dict) and "raw_audit" in inner:
        inner = dict(inner)
        inner.pop("raw_audit", None)
    rec["raw_audit"] = inner
    if isinstance(rec.get("raw_audit"), dict):
        for k in ("answer", "fact", "verified_context", "id"):
            rec["raw_audit"].pop(k, None)
    return rec

def load_json(path: str) -> Any:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def append_jsonl(path: str, obj: Dict[str, Any]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)

    # ğŸ”’ FINAL SAFETY NET: flatten raw_audit before writing
    obj = _sanitize_record(obj)

    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")



def read_done_ids(jsonl_path: str) -> Set[str]:
    done: Set[str] = set()
    if not os.path.exists(jsonl_path):
        return done
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
                _id = str(obj.get("id", ""))
                if _id:
                    done.add(_id)
            except Exception:
                continue
    return done


def normalize_item(item: Dict[str, Any], idx: int) -> Dict[str, Any]:
    """
    å°½é‡å…¼å®¹ dataset çš„ä¸åŒå­—æ®µåã€‚
    ä½ å¯ä»¥ä¹‹åæŒ‰ä½ çš„çœŸå® schema å†ç²¾ç®€ã€‚
    """
    # ç»™æ¯æ¡æ•°æ®ä¸€ä¸ªç¨³å®š idï¼ˆä¼˜å…ˆç”¨æ•°æ®é‡Œè‡ªå¸¦çš„ idï¼‰
    _id = item.get("id") or item.get("qid") or item.get("uuid") or f"idx_{idx}"
    _id = str(_id)

    # å¸¸è§å­—æ®µåå…œåº•
    fact = (
        item.get("original_fact")
        or item.get("question")
        or item.get("query")
        or item.get("prompt")
        or ""
    )

    answer = (
        item.get("answer")
        or item.get("response")
        or item.get("model_answer")
        or item.get("output")
        or ""
    )

    return {
        "id": _id,
        "fact": fact,
        "answer": answer,
        "raw": item,
    }


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", default="data/dataset.json")
    parser.add_argument("--out_jsonl", default="output/audit_results.jsonl")
    parser.add_argument("--report", default="output/final_audit_report.json")
    parser.add_argument("--limit", type=int, default=0, help="0 means all")
    parser.add_argument("--start", type=int, default=0, help="start index in dataset")
    parser.add_argument("--sleep", type=float, default=0.0, help="sleep seconds per item")
    parser.add_argument("--retries", type=int, default=2, help="retries per item on API error")
    args = parser.parse_args()

    # 1. ã€æ–°å¢ã€‘ä»ç¯å¢ƒå˜é‡è·å– Purple Agent çš„åœ°å€
    # AgentBeats è¿è¡Œå®¹å™¨æ—¶ï¼Œé€šå¸¸ä¼šæŠŠå¯¹æ–¹çš„åœ°å€é€šè¿‡ç¯å¢ƒå˜é‡ä¼ è¿›æ¥
    # å¦‚æœæœ¬åœ°æµ‹è¯•ï¼Œå¯ä»¥é»˜è®¤å¡« http://localhost:8080/chat (å–å†³äº Purple Agent ç«¯å£)
    purple_url = os.getenv("PURPLE_AGENT_URL") 
    if not purple_url:
        print("Warning: PURPLE_AGENT_URL not set. Make sure to set it via -e or assume local.")

    dataset = load_json(args.dataset)
    

    # dataset å¯èƒ½æ˜¯ dict åŒ…ä¸€å±‚ï¼Œä¹Ÿå¯èƒ½ç›´æ¥æ˜¯ list
    if isinstance(dataset, dict):
        # å¸¸è§ keyï¼šdata / items / samples
        for k in ["data", "items", "samples", "dataset"]:
            if k in dataset and isinstance(dataset[k], list):
                dataset = dataset[k]
                break

    if not isinstance(dataset, list):
        raise RuntimeError(f"dataset format unexpected: {type(dataset)}")

    total_n = len(dataset)
    start = max(0, args.start)
    end = total_n if args.limit <= 0 else min(total_n, start + args.limit)

    done_ids = read_done_ids(args.out_jsonl)

    rag = GreenRAGEngine()
    auditor = TrafficLightAuditor()  # ä¼šä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ JUDGE_MODEL

    stats = {
        "total": 0,
        "skipped_done": 0,
        "green": 0,
        "yellow": 0,
        "red": 0,
        "errors": 0,
        "avg_score_sum": 0.0,
        "avg_score_count": 0,
        "model": os.getenv("JUDGE_MODEL", ""),
        "dataset": args.dataset,
        "out_jsonl": args.out_jsonl,
        "start": start,
        "end": end,
    }

    pbar = tqdm(range(start, end), total=(end - start))
    for idx in pbar:
        item = dataset[idx]
        if not isinstance(item, dict):
            item = {"value": item}

        norm = normalize_item(item, idx)
        _id = norm["id"]

        if _id in done_ids:
            stats["skipped_done"] += 1
            continue

        fact = str(norm["fact"])
        # answer = str(norm["answer"])
        # æ–°ä»£ç ï¼ˆå®æ—¶è°ƒç”¨ Purple Agentï¼‰ï¼š
        answer = ""
        fetch_error = None
        
        # åªæœ‰åœ¨è®¾ç½®äº† URL æ—¶æ‰å»è¯·æ±‚ï¼Œå¦åˆ™ fallback åˆ°æ–‡ä»¶é‡Œçš„ç­”æ¡ˆï¼ˆæ–¹ä¾¿æœ¬åœ°è°ƒè¯•ï¼‰
        if purple_url:
            try:
                # æ„é€ è¯·æ±‚ä½“ï¼šè¿™å–å†³äºä½ çš„ Purple Agent æœŸæœ›ä»€ä¹ˆæ ¼å¼
                # å¸¸è§æ ¼å¼ 1: {"query": "é—®é¢˜..."}
                # å¸¸è§æ ¼å¼ 2: {"messages": [{"role": "user", "content": "é—®é¢˜..."}]}
                payload = {"query": fact} 
                
                # å‘é€ POST è¯·æ±‚
                resp = requests.post(purple_url, json=payload, timeout=60)
                resp.raise_for_status()
                
                # è§£æè¿”å›ç»“æœï¼šåŒæ ·å–å†³äº Purple Agent è¿”å›ä»€ä¹ˆæ ¼å¼
                resp_json = resp.json()
                answer = resp_json.get("answer") or resp_json.get("response") or resp_json.get("output") or str(resp_json)
                
            except Exception as e:
                fetch_error = f"PurpleAgentCallError: {str(e)}"
                print(f"\n[Error] Failed to call Purple Agent for id={_id}: {e}")
        else:
            # å¦‚æœæ²¡é… URLï¼Œå…¼å®¹æ—§æ¨¡å¼ï¼Œè¯»æ–‡ä»¶é‡Œçš„ç­”æ¡ˆ
            answer = str(norm["answer"])

        # å¦‚æœè¯·æ±‚å¤±è´¥æˆ–æ²¡æ‹¿åˆ°ç­”æ¡ˆï¼Œè®°å½•é”™è¯¯å¹¶è·³è¿‡åç»­æ‰“åˆ†
        if fetch_error or not answer:
            stats["errors"] += 1
            append_jsonl(args.out_jsonl, {
                "id": _id,
                "error": fetch_error or "Empty answer from Purple Agent",
                "fact": fact,
                "answer": ""
            })
            continue

        # ä½ çš„åŸè„šæœ¬é‡Œæ˜¯ rag.retrieve_ground_truth(original_fact)
        verified_context = rag.retrieve_ground_truth(fact)

        last_err: Optional[str] = None
        audit: Optional[Dict[str, Any]] = None

        for attempt in range(args.retries + 1):
            try:
                audit = auditor.evaluate_signal(fact, verified_context, answer)
                last_err = None
                break
            except Exception as e:
                last_err = f"{type(e).__name__}: {e}"
                time.sleep(1.5 * (attempt + 1))

        if audit is None:
            stats["errors"] += 1
            append_jsonl(args.out_jsonl, {
                "id": _id,
                "error": last_err,
                "fact": fact,
                "answer": answer,
            })
            continue

        signal = str(audit.get("signal") or audit.get("verdict") or "YELLOW").upper()
        score = float(audit.get("score", 0.5))

        stats["total"] += 1
        stats["avg_score_sum"] += score
        stats["avg_score_count"] += 1

        if signal == "GREEN":
            stats["green"] += 1
        elif signal == "RED":
            stats["red"] += 1
        else:
            stats["yellow"] += 1

        append_jsonl(args.out_jsonl, {
            "id": _id,
            "signal": signal,
            "score": score,
            "reason": audit.get("reason", ""),
            "raw_audit": audit,
            "fact": fact,
            "answer": answer,
            "verified_context": verified_context,
        })

        done_ids.add(_id)

        # è¿›åº¦æ¡æ˜¾ç¤º
        avg = (stats["avg_score_sum"] / stats["avg_score_count"]) if stats["avg_score_count"] else 0.0
        pbar.set_postfix({
            "G": stats["green"],
            "Y": stats["yellow"],
            "R": stats["red"],
            "err": stats["errors"],
            "avg": f"{avg:.3f}",
        })

        if args.sleep > 0:
            time.sleep(args.sleep)

        # æ¯ 200 æ¡é¡ºæ‰‹æ›´æ–°ä¸€æ¬¡æŠ¥å‘Šï¼ˆé˜²å´©ï¼‰
        if stats["total"] % 200 == 0:
            avg = (stats["avg_score_sum"] / stats["avg_score_count"]) if stats["avg_score_count"] else 0.0
            report = dict(stats)
            report["avg_score"] = avg
            with open(args.report, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

    # æœ€ç»ˆæŠ¥å‘Š
    avg = (stats["avg_score_sum"] / stats["avg_score_count"]) if stats["avg_score_count"] else 0.0
    report = dict(stats)
    report["avg_score"] = avg
    with open(args.report, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nDone. Results appended to: {args.out_jsonl}")
    print(f"Report written to: {args.report}")


if __name__ == "__main__":
    main()
